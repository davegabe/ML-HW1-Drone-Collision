\section{Introduction}
In this report I will describe the implementation for the given two tasks (classification and regression) about collision detection of drones in a 2D environment.

\subsection{Dataset}
The dataset is the one provided by the course, it contains 1000 samples of drone collisions in a 2D environment. The dataset contains the following features:
\begin{itemize}
    \item \textbf{For 5 UAVs} (where i is the UAV number):
    \begin{itemize}
        \item \textbf{UAV\_i\_track}: clockwise angle from north between the i-th UAV and its target (0, 2*pi)
        \item \textbf{UAV\_i\_x}: x coordinate of the i-th UAV
        \item \textbf{UAV\_i\_y}: y coordinate of the i-th UAV
        \item \textbf{UAV\_i\_vx}: x velocity of the i-th UAV
        \item \textbf{UAV\_i\_vy}: y velocity of the i-th UAV
        \item \textbf{UAV\_i\_target\_x}: x coordinate of the i-th UAV target
        \item \textbf{UAV\_i\_target\_y}: y coordinate of the i-th UAV target
    \end{itemize}
    \item \textbf{num\_collisions}: number of collisions for the sample (0, 1, 2, 3, 4)
    \item \textbf{min\_CPA}: minimum CPA in the sample (an estimated point in which the distance between two objects, of which at least one is in motion, will reach its minimum value)
\end{itemize}
The dataset is unbalanced, as it contains 1000 samples divided into 5 classes that represent the number of collisions in the sample, as shown in (Fig.~\ref{fig:dataset_distribution}).
This is also due to the fact that the distribution of the number of collisions is not uniform.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{../results/distribution.png}
    \caption{The dataset is composed of 1000 samples divided into 5 classes that represent the number of collisions.}
    \label{fig:dataset_distribution}
\end{figure}


\subsection{Classification}
The classification task is to predict the number of collisions in a sample. I will use several classification algorithms to compare their performance. The algorithms I will use are:
\begin{itemize}
    \item \textbf{Logistic Regression}
    \item \textbf{Random Forest}
    \item \textbf{Support Vector Machine}
    \item \textbf{Gaussian Naive Bayes}
\end{itemize}
Since the dataset is unbalanced, I expect better results from Random Forest and Support Vector Machine, as they are able to handle unbalanced datasets.
The following metrics will be used to evaluate the performance of the algorithms:
\begin{itemize}
    \item \textbf{Accuracy}: measures how often the classifier makes the correct prediction
    \item \textbf{Precision}: measures the model's ability to avoid false positives
    \item \textbf{Recall}: measures the model's ability to avoid false negatives
    \item \textbf{F1-Score}: the harmonic mean of precision and recall
\end{itemize}
Since the dataset is unbalanced, I will use the F1-Score as the main metric to evaluate the performance of the algorithms.

\subsection{Regression}
The regression task is to predict the minimum CPA in a sample. I will use the following regression algorithms to compare their performance:
\begin{itemize}
    \item \textbf{Support Vector Regression}
    \item \textbf{Gradient Boosting Regression}
\end{itemize}
The following metrics will be used to evaluate the performance of the algorithms:
\begin{itemize}
    \item \textbf{Mean Squared Error}: the average of the squared differences between the predictions and the actual values
    \item \textbf{R2 Score}: the coefficient of determination, which is a measure of how well the predictions fit the actual values
\end{itemize}
